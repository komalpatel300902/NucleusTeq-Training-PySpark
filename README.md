## PySpark

### Intoduction
Databricks is a cloud-based data engineering, machine learning, and analytics platform that provides a unified environment for data processing and collaboration.

### Study Material

Youtube : [*Manish Sir*](https://youtube.com/playlist?list=PLTsNSGeIpGnGjaMSYVlidqVWSjKWoBhbr&si=Yu09Lgwtc-D0MSe9)

***Note :*** Some .ipynb I have written using databrick in which `you don't have to create spark object`. If you run those file in jupyter notebook create  the `SparkSession` object first.
### Practice 
1. [**Read CSV file**](/src/databricks_file/read_csv_file_in_spark.ipynb)
1. [**Schema Creation**](/src/databricks_file/schema_creation.ipynb)
1. [**Handling Corrupted Record**](/src/databricks_file/handling_courrupted_record.ipynb)
1. [**Reading Json file**](/src/jupyter_notebook/reading_json_file.ipynb)
1. [**Writing File on disk**](/src/databricks_file/writing_csv_file_on_disk.ipynb)
1. [**Partition and Bucketing while saving**](/src/databricks_file/partition_and_bucketing.ipynb)
1. [**Select function in pyspark**](/src/databricks_file/select_function_in_the_dataset.ipynb)